Tactical driving decisions of unmanned ground vehicles in complex highway environments: A deep reinforcement learning approach
Wang H., Yuan S., Guo M., Chan C.-Y., Li X., Lan W.
2020
In this study, a deep reinforcement learning approach is proposed to handle tactical driving in complex highway traffic environments for unmanned ground vehicles. Tactical driving is a challenging topic for unmanned ground vehicles because of its interplay with routing decisions as well as real-time traffic dynamics. The core of our deep reinforcement learning approach is a deep Q-network that takes dynamic traffic information as input and outputs typical tactical driving decisions as action. The reward is designed with the consideration of successful highway exit, average traveling speed, and driving safety and comfort. In order to endow an unmanned ground vehicle with situational traffic information that is critical for tactical driving, the vehicleA cent a,a,, cent s sensor information such as vehicle position and velocity are further augmented through the assessment of the ego-vehicleA cent a,a,, cent s collision risk, potential field, and kinematics and used as input for the deep Q-network model. A convolutional neural network is built and fine-tuned to extract traffic features which facilitate the decision-making process of Q-learning. For model training and testing, a highway simulation platform is constructed with realistic parameter settings obtained from a real-world highway traffic dataset. The performance of the deep Q-network model is validated with extensive simulation experiments under different parameter settings such as traffic density and risk level. The results exhibit the important potentials of our deep Q-network model in learning challenging tactical driving decisions given multiple objectives and complex traffic environment. A,A(C) IMechE 2020.
deep reinforcement learning; Intelligent vehicles; potential field; safety assessment; tactical driving decision
